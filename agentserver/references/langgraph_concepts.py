import os
from dotenv import load_dotenv
from typing import TypedDict
from langgraph.graph import StateGraph, START, END
from langchain_openai import ChatOpenAI

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ì˜ˆ: OPENAI_API_KEY)
load_dotenv()

# -------------------------
# 1ï¸âƒ£ ìƒíƒœ(State) ì •ì˜
# -------------------------
class ChatState(TypedDict, total=False):
    """LangGraphì—ì„œ ì‚¬ìš©í•  ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤"""
    user_message: str         # ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì§ˆë¬¸
    search_results: str       # ê²€ìƒ‰ ê²°ê³¼ ì €ì¥
    bot_response: str         # ì±—ë´‡ ì‘ë‹µ ì €ì¥
    needs_search: bool        # ê²€ìƒ‰ì´ í•„ìš”í•œì§€ ì—¬ë¶€
    correction_attempts: int  # ì§ˆë¬¸ ë³´ì • ì‹œë„ íšŸìˆ˜ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    relevance_score: str      # ê²€ìƒ‰ ê²°ê³¼ ê´€ë ¨ì„± í‰ê°€ (ì¶”ê°€)

# -------------------------
# 2ï¸âƒ£ ë…¸ë“œ(Node) í•¨ìˆ˜ ì •ì˜
# -------------------------
def receive_message(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°›ì•„ ìƒíƒœì— ì €ì¥í•˜ëŠ” ë…¸ë“œ
    """
    state["user_message"] = state.get("user_message", "")
    state["correction_attempts"] = 0  # ë³´ì • ì‹œë„ íšŸìˆ˜ ì´ˆê¸°í™”
    return state

def analyze_message(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨í•˜ëŠ” ë…¸ë“œ
    """
    message = state.get("user_message", "").lower()
    state["needs_search"] = "ê²€ìƒ‰" in message  # "ê²€ìƒ‰"ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ ê²€ìƒ‰ ìˆ˜í–‰
    return state

def perform_search(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” ë…¸ë“œ (ì‹¤ì œ ê²€ìƒ‰ ëŒ€ì‹  ì˜ˆì œ ë°ì´í„° ì‚¬ìš©)
    """
    # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš°, ì˜ˆì œ ë°ì´í„°ë¥¼ ì¶”ê°€
    if state.get("needs_search", False):
        state["search_results"] = "LangGraphëŠ” ê·¸ë˜í”„ ê¸°ë°˜ RAGë¥¼ êµ¬í˜„í•˜ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤."
    else:
        state["search_results"] = ""  # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
    return state

def evaluate_results(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ê²€ìƒ‰ëœ ê²°ê³¼ê°€ ì§ˆë¬¸ê³¼ ê´€ë ¨ì„±ì´ ìˆëŠ”ì§€ í‰ê°€í•˜ëŠ” ë…¸ë“œ
    """
    if state.get("search_results"):
        state["relevance_score"] = "GOOD"  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì ì ˆí•¨
    else:
        state["relevance_score"] = "BAD"  # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
    return state

def correct_query(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•  ê²½ìš° ì§ˆë¬¸ì„ ë³´ì •í•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë…¸ë“œ
    """
    state["correction_attempts"] += 1  # ë³´ì • ì‹œë„ íšŸìˆ˜ ì¦ê°€
    if state["correction_attempts"] > 2:  # ë¬´í•œ ë£¨í”„ ë°©ì§€
        state["needs_search"] = False  # ë” ì´ìƒ ê²€ìƒ‰ ì‹œë„í•˜ì§€ ì•ŠìŒ
    else:
        state["user_message"] = "LangGraphì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì„ ê²€ìƒ‰í•´ì£¼ì„¸ìš”."
    return state

def generate_response(state: ChatState) -> ChatState:
    """
    ğŸ“Œ LLMì„ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë…¸ë“œ
    """
    llm = ChatOpenAI(model="gpt-3.5-turbo")  # GPT-3.5 ëª¨ë¸ ì‚¬ìš©
    messages = [
        {"role": "system", "content": "ë‹¹ì‹ ì€ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤."},
        {"role": "user", "content": state.get("user_message", "")},
    ]
    if state.get("search_results"):
        messages.append({"role": "system", "content": f"ê²€ìƒ‰ ê²°ê³¼: {state['search_results']}"})

    # deprecated ëœ í˜¸ì¶œ ë°©ì‹ì„ invokeë¡œ ë³€ê²½
    response = llm.invoke(messages)
    # ë°˜í™˜ëœ responseê°€ AIMessage ê°ì²´ì´ë¯€ë¡œ, content ì†ì„±ì„ í†µí•´ ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì˜´
    state["bot_response"] = response.content
    return state


def end_conversation(state: ChatState) -> ChatState:
    """
    ğŸ“Œ ëŒ€í™”ë¥¼ ì¢…ë£Œí•˜ëŠ” ë…¸ë“œ
    """
    return state

# -------------------------
# 3ï¸âƒ£ ê·¸ë˜í”„(Graph) ìƒì„± ë° êµ¬ì„±
# -------------------------
def create_chatbot_graph() -> StateGraph:
    # âœ… StateGraph ê°ì²´ ìƒì„±
    chatbot_graph = StateGraph(ChatState)

    # âœ… ë…¸ë“œ ì¶”ê°€
    chatbot_graph.add_node("receive_message", receive_message)
    chatbot_graph.add_node("analyze_message", analyze_message)
    chatbot_graph.add_node("perform_search", perform_search)
    chatbot_graph.add_node("evaluate_results", evaluate_results)
    chatbot_graph.add_node("correct_query", correct_query)
    chatbot_graph.add_node("generate_response", generate_response)
    chatbot_graph.add_node("end_conversation", end_conversation)

    # âœ… ì—£ì§€ ì¶”ê°€ (ë…¸ë“œ ê°„ ì—°ê²°)
    chatbot_graph.add_edge(START, "receive_message")
    chatbot_graph.add_edge("receive_message", "analyze_message")
    chatbot_graph.add_edge("analyze_message", "perform_search")
    chatbot_graph.add_edge("perform_search", "evaluate_results")

    # âœ… ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (ê²€ìƒ‰ ê²°ê³¼ í‰ê°€ í›„ íë¦„ ê²°ì •)
    def decide_next_node(state: ChatState) -> str:
        """
        ğŸ“Œ evaluate_results ë…¸ë“œ ì´í›„ íë¦„ì„ ê²°ì •í•˜ëŠ” ì¡°ê±´ë¶€ ì—£ì§€
        """
        if state["relevance_score"] == "BAD" and state["correction_attempts"] < 2:
            return "correct_query"  # ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì ì ˆí•˜ë©´ ì§ˆë¬¸ì„ ìˆ˜ì •í•˜ì—¬ ë‹¤ì‹œ ê²€ìƒ‰
        return "generate_response"  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì ì ˆí•˜ë©´ ë°”ë¡œ ë‹µë³€ ìƒì„±

    chatbot_graph.add_conditional_edges(
        "evaluate_results",
        decide_next_node,
        {"correct_query": "correct_query", "generate_response": "generate_response"}
    )

    # âœ… ìˆ˜ì •ëœ ì§ˆë¬¸ìœ¼ë¡œ ë‹¤ì‹œ ê²€ìƒ‰ í›„ í‰ê°€
    chatbot_graph.add_edge("correct_query", "perform_search")

    # âœ… ë‹µë³€ ìƒì„± í›„ ì¢…ë£Œ
    chatbot_graph.add_edge("generate_response", "end_conversation")
    chatbot_graph.add_edge("end_conversation", END)

    # âœ… ê·¸ë˜í”„ ì»´íŒŒì¼
    return chatbot_graph.compile()

# -------------------------
# 4ï¸âƒ£ ê·¸ë˜í”„ ì‹¤í–‰
# -------------------------
if __name__ == "__main__":
    # âœ… ì´ˆê¸° ìƒíƒœ ì„¤ì •
    initial_state = {"user_message": "LangGraphì— ëŒ€í•´ ê²€ìƒ‰í•´ì¤˜"}

    # âœ… ê·¸ë˜í”„ ìƒì„± ë° ì‹¤í–‰
    compiled_graph = create_chatbot_graph()
    final_state = compiled_graph.invoke(initial_state)

    # âœ… ì±—ë´‡ì˜ ìµœì¢… ì‘ë‹µ ì¶œë ¥
    print("ì±—ë´‡ ì‘ë‹µ:", final_state.get("bot_response", "ì‘ë‹µ ì—†ìŒ"))
